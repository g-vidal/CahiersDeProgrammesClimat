{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "\n",
    "|  |\n",
    "| ------------------------------------------------------- | \n",
    "| ![Tremplin des sciences](../images/tremplinColorSmall.png) | \n",
    "\n",
    "Cahier d'exercices pour l'enseignement du changement climat climatique ou l'apprentissage de programmation issu de la collection \"Climat et météo tremplin pour l'enseignement des sciences\" (PIA IFÉ ENS de Lyon - Météofrance ENM Toulouse). Le dispositif clef en main repose sur l'utilisation d'une RaspberryPi chargée avec le système d'exploitation Debian enrichi, produit par le projet. Les sources et les exécutables sont accessibles dans [l'espace collaboratif du pojet à l'IFÉ ENS de Lyon](https://contrib-tremplin.ens-lyon.fr/) et une copie se trouve dans [l'espace collaboratif de la forge github](https://github.com/g-vidal/CahierDeProgrammes); plus d'information sur les [blogs d'accompagnement](http://blog.climatetmeteo.fr/GerardVidal/) systèmes d'exploitation sur [la page des OS  de Raspberries Pi](http://mediaserv.climatetmeteo.fr/images/RaspBerry/DebianStretchPi3/).  Toutes les ressources issues du projet sont fournies sous licence [Creative Commons](https://creativecommons.org/licenses/by-nc/4.0/) ou sous les licences libres d'origine des outils utilisés. \n",
    "\n",
    "Les ressources  du projet **peuvent être utilisées dans tout autre environnement compatible**, notamment tous les cahiers d'exercices peuvent être exécutés sur toute machine disposant d'un python3  et des bibliothèques jupyter, jupyterlab, numpy, netcdf4. \n",
    "\n",
    "Les données _pré-traitées_ utilisées ci-dessous sont **accessibles  en ligne** sur le [serveur de données géolocalisées](http://geoloc-tremplin.ens-lyon.fr/climato-data/) `opendap` du projet tremplin.\n",
    "\n",
    "![licence : Creative Commons](../images/Licence.jpg) \n",
    "\n",
    "Auteur : G. Vidal\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une approche des enseignements autour du changement climatique : mitigation et adaptation au changement\n",
    "# _Phase 2 : Création d'un jeu de données_\n",
    "\n",
    "Ce cahier d'exercices `ipython` propose une méthode d'exploration d'un jeu de données issues des simulations climatiques de Météofrance à partir d'une série de fichiers issus de [DRIAS](http://www.drias-climat.fr/), concertis par le cahier d'exercice _\"Phase 1 de cette série\"_. Le lot utilisé  est issu de trois séries de modélisations  RCP 2.6 - 4.5 - 8.5 CNRM sur une grille 10 x 10 centrée sur la ville de Lyon. Le travail a été effectué avec la température maximale, la température minimale  et la pluviométrie (soit neuf fichiers source). Les données extraites de  [DRIAS](http://www.drias-climat.fr/) peuvent contenir d'autres variables non abordées ici mais les programmes ci-dessous peuvent aisément être transposés aux varables souhaitées.  \n",
    "\n",
    "Cette seconde partie propose une méhode pour qu'un enseignant puisse extraire les données dont il a besoin d'une série de fichiers commandés sur le site [DRIAS](http://www.drias-climat.fr/), convertis et mis en ligne sur le [site du plojet](http://geoloc-tremplin.ens-lyon.fr/climato-data/). Ce site regroupe tous les échantillons produits par le projet et toutes les contributions fournies librement en suivant la procédure de la Phase1. \n",
    "\n",
    "Tous les cahiers de programmes sont libres et sous licence `creative commons` Ils sont accessibles sur la [forge du projet](https://contrib-tremplin.ens-lyon.fr/forge/). Ce cahier permet de produire un jeu de données Température/Pluviométrie autour de Lyon qui sera utilisé pour visualiser des courbes et des cartes en Phase3. Il peut être aisément modifié pour exploiter d'autres jeux de données du [site](http://geoloc-tremplin.ens-lyon.fr/climato-data/). Les cahiers d'exercices `ipython` créés peuvent être déposés et partagés sur la [forge du projet](https://contrib-tremplin.ens-lyon.fr/forge/)\n",
    "\n",
    "Ce cahier manipule des données multidimensionnelles il est directement opérationnel et peut être simplement exécuté dans jupyter toutefois il doit être réservé à des étudiants avancés si on souhaite en analyser le code. Ce cahier utilise les données d'un carré 10 x 10 noeuds de la grille ALADIN centré sur la ville de Lyon. Le format d'entrée et de sortie est celui utilisé par les labos de climatologie, d'océanographie : `netCDF`.  Cet outil requiert l'installation des outils `netCDF4` et `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de l'environnement et aperçu du fichier de données\n",
    "\n",
    "Importer d'abord le module `netcdf4` et `numpy`, attention les majuscules sont impératives pour le nom `netCDF4`. Ces deux modules permettent de traiter  les fichiers multidimensionnels au format netCDF utilisés dans le monde de la météorologie et de l'océanographie principalement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from array import array\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données de températures maximales depuis le fichier obtenu auprès du site [DRIAS](https://drias-prod.meteo.fr/okapi/accueil/okapiWebDrias/index.jsp) pour la région lyonnaise et intégration dans un fichier pour le traitement, puis affichage de la description du contenu, de la liste des variables.\n",
    "\n",
    "L'exemple choisi ici a été réalisé avec une grille de 10 x 10 noeuds centrés sur la ville de Lyon, pour obtenir un jeu de données depuis le site [DRIAS](https://drias-prod.meteo.fr/okapi/accueil/okapiWebDrias/index.jsp) se reporter au manuel numérique réalisé par E. Le Jan et C. Larose dans le cadre du projet \"Climat et Météo Tremplin pour l'enseignement des sciences\". \n",
    "\n",
    "Le bloc de code ci-dessous est fourni à des fins de _\"nettoyage et information\"_ il n'est pas nécessaire de l'exécuter pour atteindre le résultat il permet d'obtenir les informations sur le fichier manipulé et enlève d'éventuelles scories d'exécutionq précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables disponibles : odict_keys(['i', 'j', 'time', 'tasmax', 'lat', 'lon', 'x', 'y'])\n",
      "Variables disponibles : odict_keys(['i', 'j', 'time', 'tasmin', 'lat', 'lon', 'x', 'y'])\n",
      "Variables disponibles : odict_keys(['i', 'j', 'time', 'rstr', 'lat', 'lon', 'x', 'y'])\n"
     ]
    }
   ],
   "source": [
    "# path = 'http://geoloc-tremplin.ens-lyon.fr/climato-data/Toulouse-1/'\n",
    "path = '/home/vidal/TremplinDesSciences/2019/ClimatLyon/ConvertedDrias/Toulouse-1/'\n",
    "\n",
    "t_max_26_thisrun = nc.Dataset(path + 'tasmax_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc',\n",
    "                              mode='r', format=\"NETCDF4\", diskless=False)\n",
    "t_max_26 = t_max_26_thisrun.variables['tasmax']\n",
    "# print('Structure et taille du tableau exporté :\\n\\t', t_max_26_thisrun.variables['tasmax'].dimensions, t_max_26.shape)\n",
    "# print('\\nPremière ligne de données :\\n', t_max_26[0, 0, :])\n",
    "# print('Dernière ligne de données :\\n', t_max_26[-1, -1, :])\n",
    "\n",
    "thisrun_date = t_max_26_thisrun.variables['time']\n",
    "print('Taille du tableau de dates - ', thisrun_date.shape)\n",
    "print('Date de début de la simulation : ', nc.num2date(thisrun_date[0], thisrun_date.units).strftime(\"%c\"))\n",
    "print('Date de fin de la simulation : ', nc.num2date(thisrun_date[-1], thisrun_date.units).strftime(\"%c\"))\n",
    "#  latitude longitude\n",
    "thisrun_lat, thisrun_lon=t_max_26_thisrun.variables['lat'], t_max_26_thisrun.variables['lon']\n",
    "print('Emprise du projet en latititude-Longitude ;\\n', thisrun_lat[0][0], '# ', thisrun_lon[0][0], ' :: ',\n",
    "      thisrun_lat[-1][-1], '# ', thisrun_lon[-1][-1])\n",
    "#  coordonnées métriques\n",
    "thisrun_x, thisrun_y=t_max_26_thisrun.variables['x'], t_max_26_thisrun.variables['y']\n",
    "print('Emprise du projet en x-y mètres ;\\n', thisrun_x[0], '# ', thisrun_y[0], ' :: ', thisrun_x[-1], '# ', thisrun_y[-1])\n",
    "thisrun_gridi, thisrun_gridj=t_max_26_thisrun.variables['i'], t_max_26_thisrun.variables['j']\n",
    "#  coordonnées grille Aladin\n",
    "print('Emprise du projet en noeuds ALADIN ;\\n', thisrun_gridi[0], '# ', thisrun_gridj[0], ' :: ', thisrun_gridi[-1], '# ',\n",
    "      thisrun_gridj[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un fichier de sauvegarde des moyennes mensuelles\n",
    "\n",
    "Il a été pris le parti d'aborder les données sous la forme de moyennes mensuelles entre 2006 et 2100, ces données pourront ensuite être exploitées pour afficher l'évolution des tendances climatiques sur des intervalles de temps choisis par l'utilisateur. Ce chapitre inclut les deux étapes de création du container puis de calcul des valeurs des moyennes.\n",
    "\n",
    "Le format choisi est le même que celui utilisé par météofrance pour fournir les données [NETCDF](https://www.unidata.ucar.edu/software/netcdf/), ce format est complexe mais permet aisément de stocker des données multidimensionnelles et il est accompagné d'outils numériques permettant d'explorer efficacement cet espace multidimensionnel.\n",
    "\n",
    "Le premier bloc **effece un fichier qui porterait le même nom** et crée un nouveau fichier vide pour accueillir les valeurs moyennes calculées pour chaque noeud de la grille  traitée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  par sécurité efface le fichier portadatain=numpy.array(['foo', 'bar'], dtype='S3')nt ce nom\n",
    "#  ! attention aux pertes possibles\n",
    "\n",
    "try:\n",
    "    os.remove('t_min-t_max-rstr_thisrun_26-45-85.nc')\n",
    "except OSError:\n",
    "    pass\n",
    "extract_params_year_month=nc.Dataset('t_min-t_max-rstr_thisrun_26-45-85.nc', mode='w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du jeu de paramètres : année mois latitude longitude x y\n",
    "\n",
    "Définition et affectation des variables où sont copiées les paramètres de la grille et où seront stockés les résultats des calculs. Les affichages permettent de vérifier la validité des données utilisées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime de départ  de l'étude :  2006 \n",
      "DateTime de fin  de l'étude :  2100 \n",
      "Durée de l'étude :  95 ans \n",
      "Nb de mois dans l'année :  12\n"
     ]
    }
   ],
   "source": [
    "#  tableau du nom des mois\n",
    "listmonth=np.array(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', \n",
    "            'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'All'])\n",
    "#  Table of each month number of days for an ordinary year\n",
    "len_month_a =[31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "#  Table of each month number of days for a leap year\n",
    "len_month_b =[31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "#  Conversion en nombre entier des années extrêmes\n",
    "# ==============================================================\n",
    "# ==  Choix de la première et de la dernière année de l'étude ==\n",
    "# ==============================================================\n",
    "first_year = 2006\n",
    "last_year = 2100\n",
    "# ==============================================================\n",
    "#  Détermination de la taille des tableaux de calcul\n",
    "size_months = len(listmonth)\n",
    "twelve_months = size_months - 1\n",
    "size_years = last_year - first_year + 1\n",
    "size_grid_i = thisrun_gridi.shape[0]\n",
    "size_grid_j = thisrun_gridj.shape[0]\n",
    "print(\"DateTime de départ  de l'étude : \", first_year, \n",
    "      \"\\nDateTime de fin  de l'étude : \", last_year, \n",
    "      \"\\nDurée de l'étude : \", size_years, 'ans',\n",
    "      \"\\nNb de mois dans l'année : \", twelve_months)\n",
    "\n",
    "# \n",
    "#  Création des dimensions du tableau mois et année sont séparés pour disjoindre les traitements sur ces variables\n",
    "# \n",
    "extract_params_year_month.createDimension('i', size_grid_i)     # latitude axis\n",
    "extract_params_year_month.createDimension('j', size_grid_j)    # longitude axis\n",
    "extract_params_year_month.createDimension('month', size_months)    # month axis\n",
    "extract_params_year_month.createDimension('year', size_years)  # year axis\n",
    "extract_params_year_month.title = 'Extrait TSMax par moyenne mensuelle de 2006 a 2100 Lyon et sa region'\n",
    "extract_params_year_month.institution = 'ENS de Lyon'\n",
    "extract_params_year_month.institute_id = 'IFE Institut Francais de l Education'\n",
    "extract_params_year_month.project_id = 'Climat et meteo tremplin pour l enseignement des sciences'\n",
    "extract_params_year_month.model_id = 'CNRM-ALADIN52'\n",
    "extract_params_year_month.product = 'output derived from Meteofrance DRIAS data'\n",
    "extract_params_year_month.contact = 'gerard.vidal@ens-lyon.fr'\n",
    "extract_params_year_month.creation_date = str(datetime.now())\n",
    "extract_params_year_month.driving_experiment_name = 'DRIAS2014'\n",
    "extract_params_year_month.experiment = 'RCP2.6 RCP4.5 RCP8.5 '\n",
    "extract_params_year_month.model = 'ALADIN-Climat'\n",
    "extract_params_year_month.author = 'Gerard Vidal'\n",
    "extract_params_year_month.comment = \"Extraction des moyennes de la region Lyonnaise de 2006 a 2100 \" \\\n",
    "                                    \"et changegement des variables\"\n",
    "\n",
    "#  Define two variables with the same names as dimensions, \n",
    "#  a conventional way to define \"coordinate variables\".\n",
    "i = extract_params_year_month.createVariable('i', 'i4', ('i', ))\n",
    "i.long_name = t_max_26_thisrun.variables['i'].long_name\n",
    "j = extract_params_year_month.createVariable('j', 'i4', ('j', ))\n",
    "j.long_name = t_max_26_thisrun.variables['j'].long_name\n",
    "lat = extract_params_year_month.createVariable('lat', 'f4', ('j', 'i'))\n",
    "lat.units = t_max_26_thisrun.variables['lat'].units\n",
    "lat.long_name = t_max_26_thisrun.variables['lat'].long_name\n",
    "lat.standard_name = t_max_26_thisrun.variables['lat'].standard_name\n",
    "lat._CoordinateAxisType = t_max_26_thisrun.variables['lat']._CoordinateAxisType\n",
    "lon = extract_params_year_month.createVariable('lon', 'f4', ('j', 'i', ))\n",
    "lon.units = t_max_26_thisrun.variables['lon'].units\n",
    "lon.long_name = t_max_26_thisrun.variables['lon'].long_name\n",
    "lon.standard_name = t_max_26_thisrun.variables['lon'].standard_name\n",
    "lon._CoordinateAxisType = t_max_26_thisrun.variables['lat']._CoordinateAxisType\n",
    "x = extract_params_year_month.createVariable('x', 'i4', ('i', ))\n",
    "x.units = t_max_26_thisrun.variables['x'].units\n",
    "x.long_name = t_max_26_thisrun.variables['x'].long_name\n",
    "x.standard_name = t_max_26_thisrun.variables['x'].standard_name\n",
    "y = extract_params_year_month.createVariable('y', 'i4', ('j', ))\n",
    "y.units = t_max_26_thisrun.variables['y'].units\n",
    "y.long_name = t_max_26_thisrun.variables['y'].long_name\n",
    "y.standard_name = t_max_26_thisrun.variables['y'].standard_name\n",
    "month = extract_params_year_month.createVariable('month', 'S3', ('month', ))\n",
    "month.units = 'month'\n",
    "month.long_name = 'month_name'\n",
    "month.standard_name = 'month_name'\n",
    "year = extract_params_year_month.createVariable('year', 'u4', ('year', ))\n",
    "year.units = 'date'\n",
    "year.long_name = 'year'\n",
    "year.standard_name = 'year'\n",
    "#  Filling variables with  source data\n",
    "i[:] = thisrun_gridi[:]\n",
    "j[:] = thisrun_gridj[:]\n",
    "lat[:] = thisrun_lat[:, :]\n",
    "lon[:] = thisrun_lon[:, :]\n",
    "x[:] = thisrun_x[:]\n",
    "y[:] = thisrun_y[:]\n",
    "#  Filling new variables\n",
    "month[:] = listmonth[:]\n",
    "dd = 0\n",
    "for date in range(first_year, last_year+1):\n",
    "    year[dd] = date\n",
    "    dd += 1\n",
    "\n",
    "t_max_26_thisrun.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Function addFileMeanTKToSet ====================================\n",
    "\n",
    "\n",
    "def add_var_temp_to_set(ii, local_path, names):\n",
    "\n",
    "    global twelve_months, len_month_a, len_month_b\n",
    "    global first_year, size_years, size_months, size_grid_j, size_grid_i\n",
    "    drias_filename = names[0]\n",
    "    var_outname = names[1]\n",
    "    var_in = names[2]\n",
    "    minmax = names[3]\n",
    "\n",
    "    print('start : ', var_outname, datetime.now())\n",
    "    name_in = local_path + drias_filename\n",
    "    name_out = 'this_set_' + var_outname\n",
    "    # open source file for one parameter\n",
    "    source_data_set = nc.Dataset(name_in, mode='r', format=\"NETCDF4\")\n",
    "\n",
    "    this_set_var = source_data_set.variables[var_in]\n",
    "    this_set_dates = source_data_set.variables['time']\n",
    "\n",
    "    # create temp netCDF to host results (netcdf cannot be returned)\n",
    "    try:\n",
    "        os.remove(name_out)\n",
    "    except OSError:\n",
    "        pass\n",
    "    netcdf_output = nc.Dataset(name_out, mode='w', format='NETCDF4')\n",
    "    netcdf_output.createDimension('i', size_grid_i)  # latitude axis\n",
    "    netcdf_output.createDimension('j', size_grid_j)  # longitude axis\n",
    "    netcdf_output.createDimension('month', size_months)  # month axis\n",
    "    netcdf_output.createDimension('year', size_years)  # year axis\n",
    "\n",
    "    netcdf_output.createVariable(var_outname, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    for thisAttr in source_data_set.variables[var_in].ncattrs():\n",
    "        netcdf_output.variables[var_outname].setncattr(thisAttr, source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "    # As we deal with temperatures that we are converting from K to C we change the \"units\" value\n",
    "    # if var == 'tasmin' or var == 'tasmax':\n",
    "    netcdf_output.variables[var_outname].setncattr('units', 'degree C')\n",
    "\n",
    "    # date of the beginning of computations (num value)\n",
    "    initial_year_date = nc.date2num(datetime(2006, 1, 1), this_set_dates.units)\n",
    "    # date of the beginning of THIS study ( num value >  initial_year_date)\n",
    "    first_year_date = nc.date2num(datetime(first_year, 1, 1), this_set_dates.units)\n",
    "    # print('shape', this_set_dates.shape)\n",
    "    # print ('initial_year_date first_year_date', initial_year_date, first_year_date)\n",
    "    # iterj varies from 0 to sizeyears\n",
    "    start_year = 0\n",
    "    stop_year = size_years\n",
    "    iteri = 0\n",
    "    yeardate = initial_year_date\n",
    "    while yeardate < first_year_date :\n",
    "        iteri += 1\n",
    "        yeardate += 24  # 24 hours a day ! we are counting in hours\n",
    "#     this_date=nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "#     print('iteri this_date', iteri, this_date)\n",
    "#     print('début -> fin, iteri= : ', start_year, stop_year, iteri)\n",
    "#     print ('theseDates[iteri] :', theseDates[iteri], theseDates[100], theseDates[1000])\n",
    "\n",
    "    for iterj in range(start_year, stop_year):\n",
    "\n",
    "        this_date = nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "        this_year = int(nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%Y\"))\n",
    "        # \n",
    "        #  Compteur permettant de suivre l'avancement du calcul et le fait que chaque année\n",
    "        #  commence bien le 1er janvier à 00h00 (suivi correct des mois et années bissextiles)\n",
    "        # \n",
    "        # print('\\r', var_outname, iterj, str(this_date), end=\"\")\n",
    "        if this_year % 4 == 0:\n",
    "            for p in range(len(len_month_b)):\n",
    "                iteriLast=iteri + len_month_b[p]\n",
    "                #  moyenne du mois année bissextile\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output.variables[var_outname][iterj, p, :, :] = \\\n",
    "                    np.mean(this_set_var[iteri:iteriLast, :, :] - 273, axis=0, dtype=np.float32)\n",
    "                iteri=iteriLast\n",
    "        else:\n",
    "            for p in range(len(len_month_a)):\n",
    "                iteriLast=iteri + len_month_a[p]\n",
    "                #  moyenne du mois année ordinaire\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output.variables[var_outname][iterj, p, :, :] = \\\n",
    "                    np.mean(this_set_var[iteri:iteriLast, :, :] - 273, axis=0, dtype=np.float32)\n",
    "                iteri=iteriLast\n",
    "        #  max ou min de l'année\n",
    "        if minmax == 'max':\n",
    "            netcdf_output.variables[var_outname][iterj, len(len_month_a), :, :] = \\\n",
    "                np.amax(netcdf_output.variables[var_outname][iterj, 0:twelve_months, :, :], axis=0)\n",
    "        elif minmax == 'min':\n",
    "            netcdf_output.variables[var_outname][iterj, len(len_month_a), :, :] = \\\n",
    "                np.amin(netcdf_output.variables[var_outname][iterj, 0:twelve_months, :, :], axis=0)\n",
    "        else:\n",
    "            print('\\nError on function min or max\\n')\n",
    "\n",
    "    print(var_outname, iterj, str(this_date), datetime.now())\n",
    "    source_data_set.close()\n",
    "    netcdf_output.close()\n",
    "\n",
    "    return ii\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul principal des moyennes par mois pour chaque noeud et toutes les années\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94 Fri Jan  1 00:00:00 2100\n",
      "Valeur moyenne 3 scénarios Tmax Lyon aout 2050 :\n",
      " 27.21591 27.036688 31.908592\n",
      "\n",
      "Valeur moyenne 3 scénarios Tmin Lyon aout 2050 :\n",
      " 16.542135 17.35004 21.048792\n",
      "\n",
      "Valeur moyenne 3 scénarios Pluvio. Lyon aout 2050 :\n",
      " 1.0227215 2.577805 0.52468824\n",
      "\n",
      "Valeur cumulée 3 scénarios Cumul Pluvio. Lyon aout 2050 :\n",
      " 31.704369 79.91196 16.265335\n",
      "\n",
      "Valeur max sur l'année 2050 :\n",
      " 27.21591 27.036688 31.908592\n",
      "\n",
      "Valeur Tmin sur l'année 2050 :\n",
      " 0.25848094 0.102317564 -0.5623496\n",
      "\n",
      "Valeur moyenne des précipitations mensuellessur l'année 2050 :\n",
      " 2.3966687 2.7075322 2.4695756\n",
      "\n",
      "Valeur cumulée sur l'année 2050 :\n",
      " 872.32086 989.03687 901.1476\n"
     ]
    }
   ],
   "source": [
    "# ========== Function add_vars_rstr_rstrc_to_set( ====================================\n",
    "\n",
    "\n",
    "def add_vars_rstr_rstrc_to_set(jj, local_path, names):\n",
    "\n",
    "    global twelve_months, len_month_a, len_month_b\n",
    "    global first_year, size_years, size_months, size_grid_j, size_grid_i\n",
    "    drias_filename = names[0]\n",
    "    # Name of the rstr variable in the new NetCDF file\n",
    "    var_outname_1 = names[1]\n",
    "    # Name of the rstrc variable in the new netCDF file\n",
    "    var_outname_2 = names[2]\n",
    "    # Name of input variable from original file\n",
    "    var_in = names[3]\n",
    "\n",
    "    print('start : ', var_outname_1, var_outname_2, datetime.now())\n",
    "    name_in = local_path + drias_filename\n",
    "    name_out_1 = 'this_set_' + var_outname_1\n",
    "    name_out_2 = 'this_set_' + var_outname_2\n",
    "    # open source file\n",
    "    source_data_set = nc.Dataset(name_in, mode='r', format=\"NETCDF4\")\n",
    "\n",
    "    this_set_var = source_data_set.variables[var_in]\n",
    "    this_set_dates = source_data_set.variables['time']\n",
    "\n",
    "    # create temp netCDF to host results (netcdf cannot be returned)\n",
    "    try:\n",
    "        os.remove(name_out_1)\n",
    "    except OSError:\n",
    "        pass\n",
    "    netcdf_output_1 = nc.Dataset(name_out_1, mode='w', format='NETCDF4')\n",
    "    try:\n",
    "        os.remove(name_out_2)\n",
    "    except OSError:\n",
    "        pass\n",
    "    netcdf_output_2 = nc.Dataset(name_out_2, mode='w', format='NETCDF4')\n",
    "    netcdf_output_1.createDimension('i', size_grid_i)  # latitude axis\n",
    "    netcdf_output_2.createDimension('i', size_grid_i)  # latitude axis\n",
    "    netcdf_output_1.createDimension('j', size_grid_j)  # longitude axis\n",
    "    netcdf_output_2.createDimension('j', size_grid_j)  # longitude axis\n",
    "    netcdf_output_1.createDimension('month', size_months)  # month axis\n",
    "    netcdf_output_2.createDimension('month', size_months)  # month axis\n",
    "    netcdf_output_1.createDimension('year', size_years)  # year axis\n",
    "    netcdf_output_2.createDimension('year', size_years)  # year axis\n",
    "\n",
    "    netcdf_output_1.createVariable(var_outname_1, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    netcdf_output_2.createVariable(var_outname_2, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    for thisAttr in source_data_set.variables[var_in].ncattrs():\n",
    "        netcdf_output_1.variables[var_outname_1].setncattr(thisAttr,\n",
    "                                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "        netcdf_output_2.variables[var_outname_2].setncattr(thisAttr,\n",
    "                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "    # The second variable : cumulated rain is added from the original file\n",
    "    netcdf_output_2.variables[var_outname_2].setncattr('standard_name', 'large_scale_cumRainfall_flux')\n",
    "\n",
    "    # date of the beginning of computations (num value)\n",
    "    initial_year_date = nc.date2num(datetime(2006, 1, 1), this_set_dates.units)\n",
    "    # date of the beginning of THIS study ( num value >  initial_year_date)\n",
    "    first_year_date = nc.date2num(datetime(first_year, 1, 1), this_set_dates.units)\n",
    "    # print('shape', this_set_dates.shape)\n",
    "    # print ('initial_year_date first_year_date', initial_year_date, first_year_date)\n",
    "    # iterj varies from 0 to sizeyears\n",
    "    start_year = 0\n",
    "    stop_year = size_years\n",
    "    iteri = 0\n",
    "    yeardate = initial_year_date\n",
    "    while yeardate < first_year_date:\n",
    "        iteri += 1\n",
    "        yeardate += 24  # 24 hours a day ! we are counting in hours\n",
    "    #     this_date=nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "    #     print('iteri this_date', iteri, this_date)\n",
    "    #     print('début -> fin, iteri= : ', start_year, stop_year, iteri)\n",
    "    #     print ('theseDates[iteri] :', theseDates[iteri], theseDates[100], theseDates[1000])\n",
    "\n",
    "    for iterj in  range(start_year, stop_year) :\n",
    "\n",
    "        this_date=nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "        this_year=int(nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%Y\"))\n",
    "        #\n",
    "        #  Compteur permettant de suivre l'avancement du calcul et le fait que chaque année\n",
    "        #  commence bien le 1er janvier à 00h00 (suivi correct des mois et années bissextiles)\n",
    "        #\n",
    "        # print('\\r', var_outname_1, iterj, str(this_date), end=\"\")\n",
    "        if this_year % 4 == 0:\n",
    "            for p in range(len(len_month_b)):\n",
    "                iteriLast = iteri + len_month_b[p]\n",
    "                #  moyenne du mois année bissextile\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output_1.variables[var_outname_1][iterj, p, :, :] = np.mean(\n",
    "                    this_set_var[iteri:iteriLast, :, :], axis=0, dtype=np.float32)\n",
    "                netcdf_output_2.variables[var_outname_2][iterj, p, :, :] = np.sum(\n",
    "                    this_set_var[iteri:iteriLast, :, :], axis=0, dtype=np.float32)\n",
    "                iteri = iteriLast\n",
    "        else:\n",
    "            for p in range(len(len_month_a)):\n",
    "                iteriLast = iteri + len_month_a[p]\n",
    "                #  moyenne du mois année ordinaire\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output_1.variables[var_outname_1][iterj, p, :, :] = np.mean(\n",
    "                    this_set_var[iteri:iteriLast, :, :], axis=0, dtype=np.float32)\n",
    "                netcdf_output_2.variables[var_outname_2][iterj, p, :, :] = np.sum(\n",
    "                    this_set_var[iteri:iteriLast, :, :], axis=0, dtype=np.float32)\n",
    "                iteri = iteriLast\n",
    "        #  somme de l'année\n",
    "        netcdf_output_1.variables[var_outname_1][iterj, len(len_month_a), :, :] = np.mean(\n",
    "            netcdf_output_1.variables[var_outname_1][iterj, 0:twelve_months, :, :], axis=0)\n",
    "        netcdf_output_2.variables[var_outname_2][iterj, len(len_month_a), :, :] = np.sum(\n",
    "            netcdf_output_2.variables[var_outname_2][iterj, 0:twelve_months, :, :], axis=0)\n",
    "\n",
    "    print(var_outname_1, iterj, str(this_date), datetime.now())\n",
    "    source_data_set.close()\n",
    "    netcdf_output_1.close()\n",
    "    netcdf_output_2.close()\n",
    "\n",
    "    return jj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les affichages suivants permettent de vérifier  que les données obtenues correspondent au format attendu et présentent des valeurs cohérentes, plusieurs types de représentation sont proposés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= Function add_var_delta_t_to_set ================================\n",
    "\n",
    "\n",
    "def add_var_delta_t_to_set(kk, local_path, names):\n",
    "\n",
    "    global twelve_months, len_month_a, len_month_b\n",
    "    global first_year, size_years, size_months, size_grid_j, size_grid_i\n",
    "    drias_filename_1 = names[0]\n",
    "    # Name of first input variable from original file\n",
    "    var_in_1 = names[1]\n",
    "    drias_filename_2 = names[2]\n",
    "    # Name of second input variable from original file\n",
    "    var_in_2 = names[3]\n",
    "    # Name of the rstr variable in the new NetCDF file\n",
    "    var_outname = names[4]\n",
    "\n",
    "    print('start : ', var_outname, datetime.now())\n",
    "    name_in_1 = local_path + drias_filename_1\n",
    "    name_in_2 = local_path + drias_filename_2\n",
    "    name_out = 'this_set_' + var_outname\n",
    "    # open source file for one parameter\n",
    "    source_data_set_1 = nc.Dataset(name_in_1, mode='r', format=\"NETCDF4\")\n",
    "    source_data_set_2 = nc.Dataset(name_in_2, mode='r', format=\"NETCDF4\")\n",
    "\n",
    "    this_set_var_1 = source_data_set_1.variables[var_in_1]\n",
    "    this_set_var_2 = source_data_set_2.variables[var_in_2]\n",
    "    this_set_dates = source_data_set_1.variables['time']\n",
    "\n",
    "    # create temp netCDF to host results (netcdf cannot be returned)\n",
    "    try:\n",
    "        os.remove(name_out)\n",
    "    except OSError:\n",
    "        pass\n",
    "    netcdf_output = nc.Dataset(name_out, mode='w', format='NETCDF4')\n",
    "    netcdf_output.createDimension('i', size_grid_i)  # latitude axis\n",
    "    netcdf_output.createDimension('j', size_grid_j)  # longitude axis\n",
    "    netcdf_output.createDimension('month', size_months)  # month axis\n",
    "    netcdf_output.createDimension('year', size_years)  # year axis\n",
    "\n",
    "    netcdf_output.createVariable(var_outname, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    for thisAttr in source_data_set_1.variables[var_in_1].ncattrs():\n",
    "        netcdf_output.variables[var_outname].setncattr(thisAttr,\n",
    "                                                       source_data_set_1.variables[var_in_1].getncattr(thisAttr))\n",
    "    # As we deal with temperatures that we are converting from K to C we change the \"units\" value\n",
    "    # if var == 'tasmin' or var == 'tasmax':\n",
    "    netcdf_output.variables[var_outname].setncattr('units', 'degree C')\n",
    "\n",
    "    # date of the beginning of computations (num value)\n",
    "    initial_year_date = nc.date2num(datetime(2006, 1, 1), this_set_dates.units)\n",
    "    # date of the beginning of THIS study ( num value >  initial_year_date)\n",
    "    first_year_date = nc.date2num(datetime(first_year, 1, 1), this_set_dates.units)\n",
    "    # print('shape', this_set_dates.shape)\n",
    "    # print ('initial_year_date first_year_date', initial_year_date, first_year_date)\n",
    "    # iterj varies from 0 to sizeyears\n",
    "    start_year = 0\n",
    "    stop_year = size_years\n",
    "    iteri = 0\n",
    "    yeardate = initial_year_date\n",
    "    while yeardate < first_year_date:\n",
    "        iteri += 1\n",
    "        yeardate += 24  # 24 hours a day ! we are counting in hours\n",
    "    #     this_date=nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "    #     print('iteri this_date', iteri, this_date)\n",
    "    #     print('début -> fin, iteri= : ', start_year, stop_year, iteri)\n",
    "    #     print ('theseDates[iteri] :', theseDates[iteri], theseDates[100], theseDates[1000])\n",
    "\n",
    "    for iterj in range(start_year, stop_year):\n",
    "\n",
    "        this_date = nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%c\")\n",
    "        this_year = int(nc.num2date(this_set_dates[iteri], this_set_dates.units).strftime(\"%Y\"))\n",
    "        #\n",
    "        #  Compteur permettant de suivre l'avancement du calcul et le fait que chaque année\n",
    "        #  commence bien le 1er janvier à 00h00 (suivi correct des mois et années bissextiles)\n",
    "        #\n",
    "        # print('\\r', var_outname, iterj, str(this_date), end=\"\")\n",
    "        if this_year % 4 == 0:\n",
    "            for p in range(len(len_month_b)):\n",
    "                iteriLast = iteri + len_month_b[p]\n",
    "                #  moyenne du mois année bissextile\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output.variables[var_outname][iterj, p, :, :] = \\\n",
    "                    np.mean((this_set_var_1[iteri:iteriLast, :, :] - this_set_var_2[iteri:iteriLast, :, :]),\n",
    "                            axis=0, dtype=np.float32)\n",
    "                iteri = iteriLast\n",
    "        else:\n",
    "            for p in range(len(len_month_a)):\n",
    "                iteriLast = iteri + len_month_a[p]\n",
    "                #  moyenne du mois année ordinaire\n",
    "                # tempo_name[iterj, p, :, :] = np.mean(this_set_var[iteri:iteriLast, :, :] - 273,\n",
    "                # axis=0, dtype=np.float32)\n",
    "                netcdf_output.variables[var_outname][iterj, p, :, :] = \\\n",
    "                    np.mean((this_set_var_1[iteri:iteriLast, :, :] - this_set_var_2[iteri:iteriLast, :, :]),\n",
    "                            axis=0, dtype=np.float32)\n",
    "                iteri = iteriLast\n",
    "        #  moyenne de l'année\n",
    "        netcdf_output.variables[var_outname][iterj, len(len_month_a), :, :] = \\\n",
    "            np.mean(netcdf_output.variables[var_outname][iterj, 0:twelve_months, :, :], axis=0)\n",
    "\n",
    "    print(var_outname, iterj, str(this_date), datetime.now())\n",
    "    source_data_set_1.close()\n",
    "    source_data_set_2.close()\n",
    "    netcdf_output.close()\n",
    "\n",
    "    return kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================== collect_resultii ========\n",
    "\n",
    "\n",
    "# def collect_resultii(result):\n",
    "    # global resultii\n",
    "#     resultii.append(result)\n",
    "\n",
    "# =================================== collect_resultjj ========\n",
    "\n",
    "\n",
    "# def collect_resultjj(result):\n",
    "    # global resultjj\n",
    "#     resultjj.append(result)\n",
    "\n",
    "# =================================== collect_resultkk ========\n",
    "\n",
    "\n",
    "# def collect_resultkk(result):\n",
    "    # global resultkk\n",
    " #    resultkk.append(result)\n",
    "\n",
    "# ============================== Listes des fichiers à traiter ==================================\n",
    "\n",
    "\n",
    "namesT = [['tasmax_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc', 't_max_26', 'tasmax', 'max'],\n",
    "          ['tasmax_metro_CNRM_Aladin_rcp4.5_QT_RCP4.5_20060101-21001231.nc', 't_max_45', 'tasmax', 'max'],\n",
    "          ['tasmax_metro_CNRM_Aladin_rcp8.5_QT_RCP8.5_20060101-21001231.nc', 't_max_85', 'tasmax', 'max'],\n",
    "          ['tasmin_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc', 't_min_26', 'tasmin', 'min'],\n",
    "          ['tasmin_metro_CNRM_Aladin_rcp4.5_QT_RCP4.5_20060101-21001231.nc', 't_min_45', 'tasmin', 'min'],\n",
    "          ['tasmin_metro_CNRM_Aladin_rcp8.5_QT_RCP8.5_20060101-21001231.nc', 't_min_85', 'tasmin', 'min']]\n",
    "\n",
    "namesP = [['rstr_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc', 'rstr_26', 'rstrc_26', 'rstr'],\n",
    "          ['rstr_metro_CNRM_Aladin_rcp4.5_QT_RCP4.5_20060101-21001231.nc', 'rstr_45', 'rstrc_45', 'rstr'],\n",
    "          ['rstr_metro_CNRM_Aladin_rcp8.5_QT_RCP8.5_20060101-21001231.nc', 'rstr_85', 'rstrc_85', 'rstr']]\n",
    "\n",
    "namesDT = [['tasmax_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc', 'tasmax',\n",
    "            'tasmin_metro_CNRM_Aladin_rcp2.6_QT_RCP2.6_20060101-21001231.nc', 'tasmin', 'delta_t_26'],\n",
    "          ['tasmax_metro_CNRM_Aladin_rcp4.5_QT_RCP4.5_20060101-21001231.nc', 'tasmax',\n",
    "           'tasmin_metro_CNRM_Aladin_rcp4.5_QT_RCP4.5_20060101-21001231.nc', 'tasmin', 'delta_t_45'],\n",
    "          ['tasmax_metro_CNRM_Aladin_rcp8.5_QT_RCP8.5_20060101-21001231.nc', 'tasmax',\n",
    "           'tasmin_metro_CNRM_Aladin_rcp8.5_QT_RCP8.5_20060101-21001231.nc', 'tasmin', 'delta_t_85']]\n",
    "\n",
    "ii = 0\n",
    "jj = 0\n",
    "kk = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================= boucle linéaire =========================================\n",
    "\n",
    "for ii, names in enumerate(namesT):\n",
    "    add_var_temp_to_set(ii, path, names)\n",
    "for jj, names in enumerate(namesP):\n",
    "    add_vars_rstr_rstrc_to_set(kk, path, names)\n",
    "for kk, names in enumerate(namesDT):\n",
    "    add_var_delta_t_to_set(kk, path, names)\n",
    "# ======================================= /boucle linéaire =========================================\n",
    "\n",
    "# ======================================= boucle parallèle =========================================\n",
    "# resultii = []\n",
    "# resultjj = []\n",
    "# resultkk = []\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "# print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "#  Températures\n",
    "# for ii, names in enumerate(namesT):\n",
    "#     pool.apply_async(add_var_temp_to_set, args=(ii, path, names), callback=collect_resultii)\n",
    "# Précipitations  et précipitations cumulées\n",
    "# for jj, names in enumerate(namesP):\n",
    "#     pool.apply_async(add_vars_rstr_rstrc_to_set, args=(kk, path, names), callback=collect_resultjj)\n",
    "\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "# A second pool is necessary to prevent parallel computing messing up values from same source\n",
    "# in multple computations\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "# print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# deltaT quotidien\n",
    "# for kk, names in enumerate(namesDT):\n",
    "#     pool.apply_async(add_var_delta_t_to_set, args=(kk, path, names), callback=collect_resultkk)\n",
    "\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "# ======================================= /boucle parallèle =========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, names in enumerate(namesT):\n",
    "\n",
    "    # source file name\n",
    "    drias_filename = names[0]\n",
    "    # output name of the variable processed\n",
    "    var_outname_1 = names[1]\n",
    "    # input name of the variable processed\n",
    "    var_in = names[2]\n",
    "    # input filename\n",
    "    name_in = path + drias_filename\n",
    "    # output filename\n",
    "    name_out = 'this_set_' + var_outname_1\n",
    "\n",
    "    # open input original file\n",
    "    source_data_set = nc.Dataset(name_in, mode='r', format=\"NETCDF4\")\n",
    "    # open as input the file bearing results of the previous calculation\n",
    "    data_set_1 = nc.Dataset(name_out, mode='r', format=\"NETCDF4\")\n",
    "    # add the processed variable to the output file\n",
    "    extract_params_year_month.createVariable(var_outname_1, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "\n",
    "    # retrieve variable attribute values from original file and write them to output\n",
    "    for thisAttr in source_data_set.variables[var_in].ncattrs():\n",
    "        extract_params_year_month.variables[var_outname_1].setncattr(thisAttr,\n",
    "                                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "    # As we deal with temperatures that we are converting from K to C we change the \"units\" value\n",
    "    # if var == 'tasmin' or var == 'tasmax':\n",
    "    extract_params_year_month.variables[var_outname_1].setncattr('units', 'degree C')\n",
    "    extract_params_year_month.variables[var_outname_1][:] = data_set_1.variables[var_outname_1][:]\n",
    "\n",
    "for jj, names in enumerate(namesP):\n",
    "\n",
    "    # source file name\n",
    "    drias_filename = names[0]\n",
    "    # Name of the rstr variable in the new NetCDF file\n",
    "    var_outname_1 = names[1]\n",
    "    # Name of the rstrc variable in the new netCDF file\n",
    "    var_outname_2 = names[2]\n",
    "    # Name of input variable from original file\n",
    "    var_in = names[3]\n",
    "    # input filename\n",
    "    name_in = path + drias_filename\n",
    "    # output 1 filename\n",
    "    name_out_1 = 'this_set_' + var_outname_1\n",
    "    # output 2 filename\n",
    "    name_out_2 = 'this_set_' + var_outname_2\n",
    "\n",
    "    # open input original file\n",
    "    source_data_set = nc.Dataset(name_in, mode='r', format=\"NETCDF4\")\n",
    "    # open as input the file bearing results of the previous calculation\n",
    "    data_set_1 = nc.Dataset(name_out_1, mode='r', format=\"NETCDF4\")\n",
    "    data_set_2 = nc.Dataset(name_out_2, mode='r', format=\"NETCDF4\")\n",
    "    # add the processed variable to the output file\n",
    "    extract_params_year_month.createVariable(var_outname_1, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    extract_params_year_month.createVariable(var_outname_2, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "\n",
    "    # retrieve variable attribute values from original file and write them to output\n",
    "    for thisAttr in source_data_set.variables[var_in].ncattrs():\n",
    "        extract_params_year_month.variables[var_outname_1].setncattr(thisAttr,\n",
    "                                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "        extract_params_year_month.variables[var_outname_2].setncattr(thisAttr,\n",
    "                                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "    # The second variable : cumulated rain is added from the original file\n",
    "    extract_params_year_month.variables[var_outname_1].setncattr('standard_name', 'largescale_cumRainfall_flux')\n",
    "    extract_params_year_month.variables[var_outname_1][:] = data_set_1.variables[var_outname_1][:]\n",
    "    extract_params_year_month.variables[var_outname_2][:] = data_set_2.variables[var_outname_2][:]\n",
    "\n",
    "for kk, names in enumerate(namesDT):\n",
    "\n",
    "    # source file name\n",
    "    drias_filename = names[0]\n",
    "    # Name of first input variable from original file\n",
    "    var_in = names[1]\n",
    "    # output name of the variable processed\n",
    "    var_outname_1 = names[4]\n",
    "    # input filename\n",
    "    name_in = path + drias_filename\n",
    "    # output filename\n",
    "    name_out = 'this_set_' + var_outname_1\n",
    "\n",
    "    # open input original file\n",
    "    source_data_set = nc.Dataset(name_in, mode='r', format=\"NETCDF4\")\n",
    "    # open as input the file bearing results of the previous calculation\n",
    "    data_set_1 = nc.Dataset(name_out, mode='r', format=\"NETCDF4\")\n",
    "    # add the processed variable to the output file\n",
    "    extract_params_year_month.createVariable(var_outname_1, 'f4', ('year', 'month', 'j', 'i'), fill_value=1.e+20)\n",
    "    for thisAttr in source_data_set.variables[var_in].ncattrs():\n",
    "        extract_params_year_month.variables[var_outname_1].setncattr(thisAttr,\n",
    "                                                                     source_data_set.variables[var_in].getncattr(thisAttr))\n",
    "    # As we deal with difference of temperatures  we change the \"units\" value\n",
    "    extract_params_year_month.variables[var_outname_1].setncattr('units', 'degree C')\n",
    "    extract_params_year_month.variables[var_outname_1][:] = data_set_1.variables[var_outname_1][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('\\n\\nextract_params_year_month contents :', extract_params_year_month.variables['t_max_26'][:])\n",
    "\n",
    "extractLyonTempYearMonth.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
